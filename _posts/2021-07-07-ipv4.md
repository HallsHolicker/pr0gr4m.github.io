---
title: "Linux Kernel IPv4"
categories: linux kernel
---

해당 포스트에서는 리눅스 커널의 IPv4 구현에 대해 설명합니다.

# IPv4

IPv4는 Packet Switching Network 상에서 데이터를 교환하기 위한 프로토콜이다.  
네트워크 계층에서 호스트의 주소 지정 및 라우팅과 패킷 분할 및 조립 기능을 담당한다.  
IPv4 상에서는 reliability와 connection을 보장하지는 않는다.  

## IPv4 헤더

![ipv4_header](https://github.com/pr0gr4m/pr0gr4m.github.io/blob/master/img/ipv4_header.png?raw=true)

IPv4 헤더는 고정된 20바이트 필드와, 0바이트에서 40바이트의 옵션 필드로 구성된다.  
커널에서 구현한 IPv4 헤더 구조체는 다음과 같다.  
```c
struct iphdr {
#if defined(__LITTLE_ENDIAN_BITFIELD)
	__u8	ihl:4,
		version:4;
#elif defined (__BIG_ENDIAN_BITFIELD)
	__u8	version:4,
  		ihl:4;
#else
#error	"Please fix <asm/byteorder.h>"
#endif
	__u8	tos;
	__be16	tot_len;
	__be16	id;
	__be16	frag_off;
	__u8	ttl;
	__u8	protocol;
	__sum16	check;
	__be32	saddr;
	__be32	daddr;
	/*The options start here. */
};
```
* ihl : Internet Header Length의 약어이다. IPv4 헤더의 길이는 4바이트 배수로 계산한다. IPv4 헤더의 크기가 20 ~ 60바이트 이기 때문에, 해당 필드는 5 ~ 15의 값을 갖는다.
* version : IPv4 헤더의 버전은 항상 4이다.
* tos : Type of Service의 약어로 원래 QoS를 나타낼 의도로 만들어진 필드이다. 실제로는 0 ~ 5 비트를 Differentiated Services 필드로 사용하고, 6 ~ 7 비트를 Explicit Congetion Notification 필드로 사용한다.
* tot_len : 헤더를 포함한 전체 길이로서 바이트 단위로 계산한다. 16비트이므로 최대 64KB까지 표현할 수 있다. RFC 791에 따라 최소 크기는 576 바이트이다.
* id : IPv4 헤더의 식별자이다. SKB를 단편화하면 단편화된 모든 SKB의 id 값이 같아야한다. 해당 필드를 이용하여 단편화된 패킷을 재조립한다.
* frag_off : 하위 13비트는 단편화의 오프셋이며 상위 3비트는 플래그이다. 첫 단편화 패킷에서는 오프셋이 0이며, 오프셋은 8바이트 단위로 계산한다. 플래그는 다음과 같다.
    * 001 : More Fragments로 마지막 하나를 제외한 모든 단편화된 패킷에 설정된다.
    * 010 : Don't Fragment로 단편화되지 않은 패킷에 대한 플래그다
    * 100 : Congetion으로 혼잡 플래그이다.
* ttl : Time To Live 필드이다. 각 포워딩 노드마다 ttl 값이 1씩 줄어들고, 0이 되면 패킷은 폐기되며 시간 초과 ICMP 메시지가 회신된다.
* protocol : 패킷의 L4 프로토콜 필드이다. IPPROTO_TCP 등이 설정되며, 해당 [링크](https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/in.h#L28) 에서 리스트를 볼 수 있다.
* check : 체크섬 필드로, IPv4 헤더 바이트에 대해서만 계산된다.
* saddr : Source IPv4 주소
* daddr : Destination IPv4 주소

## IPv4 초기화

IPv4 초기화는 다음과 같이 부팅 시에 inet_init() 함수에서 진행한다.

```c
static struct packet_type ip_packet_type __read_mostly = {
	.type = cpu_to_be16(ETH_P_IP),
	.func = ip_rcv,
	.list_func = ip_list_rcv,
};

static int __init inet_init(void)
{
	struct inet_protosw *q;
	struct list_head *r;
	int rc;
	...
#ifdef CONFIG_SYSCTL
	ip_static_sysctl_init();
#endif
	...
	/*
	 *	Set the IP module up
	 */
	ip_init();
	...
	/*
	 *	Initialise the multicast router
	 */
#if defined(CONFIG_IP_MROUTE)
	if (ip_mr_init())
		pr_crit("%s: Cannot init ipv4 mroute\n", __func__);
#endif
	...
	if (init_inet_pernet_ops())
		pr_crit("%s: Cannot init ipv4 inet pernet ops\n", __func__);
	/*
	 *	Initialise per-cpu ipv4 mibs
	 */

	if (init_ipv4_mibs())
		pr_crit("%s: Cannot init ipv4 mibs\n", __func__);

	ipv4_proc_init();

	ipfrag_init();

	dev_add_pack(&ip_packet_type);

	ip_tunnel_core_init();
	...
}

#ifdef CONFIG_PROC_FS
static int __init ipv4_proc_init(void)
{
	int rc = 0;

	if (raw_proc_init())
		goto out_raw;
	if (tcp4_proc_init())
		goto out_tcp;
	if (udp4_proc_init())
		goto out_udp;
	if (ping_proc_init())
		goto out_ping;
	if (ip_misc_proc_init())
		goto out_misc;
out:
	return rc;
out_misc:
	ping_proc_exit();
out_ping:
	udp4_proc_exit();
out_udp:
	tcp4_proc_exit();
out_tcp:
	raw_proc_exit();
out_raw:
	rc = -ENOMEM;
	goto out;
}

#else /* CONFIG_PROC_FS */
static int __init ipv4_proc_init(void)
{
	return 0;
}
#endif /* CONFIG_PROC_FS */

void __init ip_init(void)
{
	ip_rt_init();
	inet_initpeers();

#if defined(CONFIG_IP_MULTICAST)
	igmp_mc_init();
#endif
}
```

dev_add_pack() 함수에서 ip_rcv() 함수를 IPv4 패킷에 대한 프로토콜 핸들러로 추가한다.  
[packet_type](https://elixir.bootlin.com/linux/latest/source/include/linux/netdevice.h#L2606) 구조체에서는 패킷의 핸들러를 등록할 수 있다.  
*list_func* 멤버는 [multiple received packets](https://lwn.net/Articles/758351/)를 처리하기 위한 listified receive 함수를 등록할 수 있다.  
IPv4 패킷은 L2 레이어에서 이더넷 타입이 [0x0800](https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/if_ether.h#L52)인 패킷으로 식별한다.  
ip_init() 함수에서는 라우팅 테이블이나 IGMP 관련 초기화를 수행한다.  

## IPv4 패킷 수신

IPv4 패킷 수신 Flow를 간단하게 도식화하면 다음과 같다.  
![ipv4_rcv](https://github.com/pr0gr4m/pr0gr4m.github.io/blob/master/img/ipv4_rcv.png?raw=true)
다이어그램 중간에 위치하는 넷필터 관련 훅들은 이 후 넷필터 챕터에서 설명한다.  
수신한 패킷은 라우팅 서브시스템 탐색을 수행한다. 목적지가 로컬 호스트라면 ip_local_deliver() 함수에 도착할 것이고, 포워딩 될 패킷이면 ip_forward() 함수로 처리될 것이다.  
위 다이어그램에서 listified packet은 ip_list_rcv()와 ip_list_rcv_finish() 함수로 처리될 것이다.  

IPv4 패킷 수신 핸들러인 ip_rcv() 함수와 ip_list_rcv() 함수는 ip_rcv_core() 함수를 호출하여 IP 수신 루틴을 처리한다.  
```c
/*
 * 	Main IP Receive routine.
 */
static struct sk_buff *ip_rcv_core(struct sk_buff *skb, struct net *net)
{
	const struct iphdr *iph;
	u32 len;

	/* When the interface is in promisc. mode, drop all the crap
	 * that it receives, do not try to analyse it.
	 */
	if (skb->pkt_type == PACKET_OTHERHOST)
		goto drop;

	__IP_UPD_PO_STATS(net, IPSTATS_MIB_IN, skb->len);

	skb = skb_share_check(skb, GFP_ATOMIC);
	if (!skb) {
		__IP_INC_STATS(net, IPSTATS_MIB_INDISCARDS);
		goto out;
	}

	if (!pskb_may_pull(skb, sizeof(struct iphdr)))
		goto inhdr_error;

	iph = ip_hdr(skb);

	/*
	 *	RFC1122: 3.2.1.2 MUST silently discard any IP frame that fails the checksum.
	 *
	 *	Is the datagram acceptable?
	 *
	 *	1.	Length at least the size of an ip header
	 *	2.	Version of 4
	 *	3.	Checksums correctly. [Speed optimisation for later, skip loopback checksums]
	 *	4.	Doesn't have a bogus length
	 */

	if (iph->ihl < 5 || iph->version != 4)
		goto inhdr_error;

	BUILD_BUG_ON(IPSTATS_MIB_ECT1PKTS != IPSTATS_MIB_NOECTPKTS + INET_ECN_ECT_1);
	BUILD_BUG_ON(IPSTATS_MIB_ECT0PKTS != IPSTATS_MIB_NOECTPKTS + INET_ECN_ECT_0);
	BUILD_BUG_ON(IPSTATS_MIB_CEPKTS != IPSTATS_MIB_NOECTPKTS + INET_ECN_CE);
	__IP_ADD_STATS(net,
		       IPSTATS_MIB_NOECTPKTS + (iph->tos & INET_ECN_MASK),
		       max_t(unsigned short, 1, skb_shinfo(skb)->gso_segs));

	if (!pskb_may_pull(skb, iph->ihl*4))
		goto inhdr_error;

	iph = ip_hdr(skb);

	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
		goto csum_error;

	len = ntohs(iph->tot_len);
	if (skb->len < len) {
		__IP_INC_STATS(net, IPSTATS_MIB_INTRUNCATEDPKTS);
		goto drop;
	} else if (len < (iph->ihl*4))
		goto inhdr_error;

	/* Our transport medium may have padded the buffer out. Now we know it
	 * is IP we can trim to the true length of the frame.
	 * Note this now means skb->len holds ntohs(iph->tot_len).
	 */
	if (pskb_trim_rcsum(skb, len)) {
		__IP_INC_STATS(net, IPSTATS_MIB_INDISCARDS);
		goto drop;
	}

	iph = ip_hdr(skb);
	skb->transport_header = skb->network_header + iph->ihl*4;

	/* Remove any debris in the socket control block */
	memset(IPCB(skb), 0, sizeof(struct inet_skb_parm));
	IPCB(skb)->iif = skb->skb_iif;

	/* Must drop socket now because of tproxy. */
	if (!skb_sk_is_prefetched(skb))
		skb_orphan(skb);

	return skb;

csum_error:
	__IP_INC_STATS(net, IPSTATS_MIB_CSUMERRORS);
inhdr_error:
	__IP_INC_STATS(net, IPSTATS_MIB_INHDRERRORS);
drop:
	kfree_skb(skb);
out:
	return NULL;
}
```

해당 함수에서는 우선 다양한 온전성 검사와 통계 업데이트 및 체크섬 계산을 수행한다.  
일부 패딩된 패킷에 대해서는 trim 작업을 수행하기도 한다.  
이 후 NF_HOOK 넷필터 훅 함수를 호출한 후, ip_rcv_finish() 혹은 ip_list_rcv_finish() 함수를 호출한다.  
해당 함수들은 결국 ip_rcv_finish_core() 함수를 호출하여 수신에 대한 메인 루틴을 처리한다.  
```c
static int ip_rcv_finish_core(struct net *net, struct sock *sk,
			      struct sk_buff *skb, struct net_device *dev,
			      const struct sk_buff *hint)
{
	const struct iphdr *iph = ip_hdr(skb);
	int (*edemux)(struct sk_buff *skb);
	struct rtable *rt;
	int err;

	if (ip_can_use_hint(skb, iph, hint)) {
		err = ip_route_use_hint(skb, iph->daddr, iph->saddr, iph->tos,
					dev, hint);
		if (unlikely(err))
			goto drop_error;
	}

	if (net->ipv4.sysctl_ip_early_demux &&
	    !skb_dst(skb) &&
	    !skb->sk &&
	    !ip_is_fragment(iph)) {
		const struct net_protocol *ipprot;
		int protocol = iph->protocol;

		ipprot = rcu_dereference(inet_protos[protocol]);
		if (ipprot && (edemux = READ_ONCE(ipprot->early_demux))) {
			err = INDIRECT_CALL_2(edemux, tcp_v4_early_demux,
					      udp_v4_early_demux, skb);
			if (unlikely(err))
				goto drop_error;
			/* must reload iph, skb->head might have changed */
			iph = ip_hdr(skb);
		}
	}

	/*
	 *	Initialise the virtual path cache for the packet. It describes
	 *	how the packet travels inside Linux networking.
	 */
	if (!skb_valid_dst(skb)) {
		err = ip_route_input_noref(skb, iph->daddr, iph->saddr,
					   iph->tos, dev);
		if (unlikely(err))
			goto drop_error;
	}

#ifdef CONFIG_IP_ROUTE_CLASSID
	if (unlikely(skb_dst(skb)->tclassid)) {
		struct ip_rt_acct *st = this_cpu_ptr(ip_rt_acct);
		u32 idx = skb_dst(skb)->tclassid;
		st[idx&0xFF].o_packets++;
		st[idx&0xFF].o_bytes += skb->len;
		st[(idx>>16)&0xFF].i_packets++;
		st[(idx>>16)&0xFF].i_bytes += skb->len;
	}
#endif

	if (iph->ihl > 5 && ip_rcv_options(skb, dev))
		goto drop;

	rt = skb_rtable(skb);
	if (rt->rt_type == RTN_MULTICAST) {
		__IP_UPD_PO_STATS(net, IPSTATS_MIB_INMCAST, skb->len);
	} else if (rt->rt_type == RTN_BROADCAST) {
		__IP_UPD_PO_STATS(net, IPSTATS_MIB_INBCAST, skb->len);
	} else if (skb->pkt_type == PACKET_BROADCAST ||
		   skb->pkt_type == PACKET_MULTICAST) {
		struct in_device *in_dev = __in_dev_get_rcu(dev);

		/* RFC 1122 3.3.6:
		 *
		 *   When a host sends a datagram to a link-layer broadcast
		 *   address, the IP destination address MUST be a legal IP
		 *   broadcast or IP multicast address.
		 *
		 *   A host SHOULD silently discard a datagram that is received
		 *   via a link-layer broadcast (see Section 2.4) but does not
		 *   specify an IP multicast or broadcast destination address.
		 *
		 * This doesn't explicitly say L2 *broadcast*, but broadcast is
		 * in a way a form of multicast and the most common use case for
		 * this is 802.11 protecting against cross-station spoofing (the
		 * so-called "hole-196" attack) so do it for both.
		 */
		if (in_dev &&
		    IN_DEV_ORCONF(in_dev, DROP_UNICAST_IN_L2_MULTICAST))
			goto drop;
	}

	return NET_RX_SUCCESS;

drop:
	kfree_skb(skb);
	return NET_RX_DROP;

drop_error:
	if (err == -EXDEV)
		__NET_INC_STATS(net, LINUX_MIB_IPRPFILTER);
	goto drop;
}
```

라우팅을 위한 작업들을 수행한다. 우선, 라우팅 테이블 lookup 전에 ip_can_use_hint() 함수로 hint 객체 사용 가능 여부와 skb_dst() 함수를 통한 dst 객체 존재 여부를 살펴본다.  

dst 객체는 [dst_entry](https://elixir.bootlin.com/linux/latest/source/include/net/dst.h#L25) 타입 인스턴스로, 라우팅 서브시스템 탐색 결과를 나타낸다.  
해당 객체의 주요 멤버로는 ```int (*input)(struct sk_buff *);```와 ```int (*output)(struct net *net, struct sock *sk, struct sk_buff *skb);``` 콜백이 있다.  
예를 들어, 라우팅 서브시스템 탐색 중에 패킷이 포워딩돼야 하면 input 멤버에 ip_forward() 함수가 설정될 것이며, 로컬 장비를 목적지로 하면 ip_local_deliver() 함수가 설정될 것이다.  

사전 작업에 의해 SKB에 적절한 dst 객체를 찾지 못한 경우 [ip_route_input_noref()](https://elixir.bootlin.com/linux/latest/source/net/ipv4/route.c#L2295) 함수로 라우팅 서브시스템 탐색을 수행한다.  
이 후 IPv4 헤더에 옵션이 있다면 ip_rcv_options() 함수로 처리하고, 라우팅 테이블 타입에 따라 통계를 업데이트한다.  

이러한 과정들에서 drop될 패킷이라면 ip_rcv_finish_core() 함수는 SKB를 할당 해제하고 NET_RX_DROP를 반환하며, 수신할 패킷이라면 NET_RX_SUCCESS를 반환한다.  
ip_rcv_finish_core() 함수가 끝나면 ip_rcv_finish() 함수는 dst_input() 함수를 호출하여 SKB에 연결된 dst 객체의 input 콜백을 호출한다.  
```c
static int ip_rcv_finish(struct net *net, struct sock *sk, struct sk_buff *skb)
{
	struct net_device *dev = skb->dev;
	int ret;

	/* if ingress device is enslaved to an L3 master device pass the
	 * skb to its handler for processing
	 */
	skb = l3mdev_ip_rcv(skb);
	if (!skb)
		return NET_RX_SUCCESS;

	ret = ip_rcv_finish_core(net, sk, skb, dev, NULL);
	if (ret != NET_RX_DROP)
		ret = dst_input(skb);		// input callback 호출
	return ret;
}

static void ip_list_rcv_finish(struct net *net, struct sock *sk,
			       struct list_head *head)
{
	struct sk_buff *skb, *next, *hint = NULL;
	struct dst_entry *curr_dst = NULL;
	struct list_head sublist;

	INIT_LIST_HEAD(&sublist);
	list_for_each_entry_safe(skb, next, head, list) {
		struct net_device *dev = skb->dev;
		struct dst_entry *dst;

		skb_list_del_init(skb);
		/* if ingress device is enslaved to an L3 master device pass the
		 * skb to its handler for processing
		 */
		skb = l3mdev_ip_rcv(skb);
		if (!skb)
			continue;
		if (ip_rcv_finish_core(net, sk, skb, dev, hint) == NET_RX_DROP)
			continue;

		dst = skb_dst(skb);
		if (curr_dst != dst) {
			hint = ip_extract_route_hint(net, skb,
					       ((struct rtable *)dst)->rt_type);

			/* dispatch old sublist */
			if (!list_empty(&sublist))
				ip_sublist_rcv_finish(&sublist);
			/* start new sublist */
			INIT_LIST_HEAD(&sublist);
			curr_dst = dst;
		}
		list_add_tail(&skb->list, &sublist);		// 패킷을 sublist에 추가
	}
	/* dispatch final sublist */
	ip_sublist_rcv_finish(&sublist);
}

static void ip_sublist_rcv_finish(struct list_head *head)
{
	struct sk_buff *skb, *next;

	list_for_each_entry_safe(skb, next, head, list) {
		skb_list_del_init(skb);
		dst_input(skb);		// input callback 호출
	}
}
```

## IPv4 멀티캐스트 패킷 수신

ip_rcv_finish_core() 함수에서 라우팅 테이블 lookup을 수행하기 위하여 ip_route_input_noref() 함수를 호출한다고 하였다.  
ip_route_input_noref() 함수에서는 RCU lock을 획득하고 다음과 같은 ip_route_input_rcu() 함수를 호출한다.  
```c
/* called with rcu_read_lock held */
int ip_route_input_rcu(struct sk_buff *skb, __be32 daddr, __be32 saddr,
		       u8 tos, struct net_device *dev, struct fib_result *res)
{
	/* Multicast recognition logic is moved from route cache to here.
	 * The problem was that too many Ethernet cards have broken/missing
	 * hardware multicast filters :-( As result the host on multicasting
	 * network acquires a lot of useless route cache entries, sort of
	 * SDR messages from all the world. Now we try to get rid of them.
	 * Really, provided software IP multicast filter is organized
	 * reasonably (at least, hashed), it does not result in a slowdown
	 * comparing with route cache reject entries.
	 * Note, that multicast routers are not affected, because
	 * route cache entry is created eventually.
	 */
	if (ipv4_is_multicast(daddr)) {
		struct in_device *in_dev = __in_dev_get_rcu(dev);
		int our = 0;
		int err = -EINVAL;

		if (!in_dev)
			return err;
		our = ip_check_mc_rcu(in_dev, daddr, saddr,
				      ip_hdr(skb)->protocol);

		/* check l3 master if no match yet */
		if (!our && netif_is_l3_slave(dev)) {
			struct in_device *l3_in_dev;

			l3_in_dev = __in_dev_get_rcu(skb->dev);
			if (l3_in_dev)
				our = ip_check_mc_rcu(l3_in_dev, daddr, saddr,
						      ip_hdr(skb)->protocol);
		}

		if (our
#ifdef CONFIG_IP_MROUTE
			||
		    (!ipv4_is_local_multicast(daddr) &&
		     IN_DEV_MFORWARD(in_dev))
#endif
		   ) {
			err = ip_route_input_mc(skb, daddr, saddr,
						tos, dev, our);
		}
		return err;
	}

	return ip_route_input_slow(skb, daddr, saddr, tos, dev, res);
}
```

패킷의 목적지 주소(iph->daddr)가 멀티캐스트 주소라면 if문 안의 문장이 실행된다.  
멀티캐스트 패킷을 수신하는 것은 로컬 호스트의 주소가 멀티캐스트 그룹에 속하거나 로컬 호스트가 멀티캐스트의 라우터인 경우이다.  
로컬 호스트가 멀티캐스트의 라우터인 경우에는 다음과 같이 ip_route_input_mc() 함수를 호출한다.  

```c
/* called in rcu_read_lock() section */
static int ip_route_input_mc(struct sk_buff *skb, __be32 daddr, __be32 saddr,
			     u8 tos, struct net_device *dev, int our)
{
	struct in_device *in_dev = __in_dev_get_rcu(dev);
	unsigned int flags = RTCF_MULTICAST;
	struct rtable *rth;
	u32 itag = 0;
	int err;

	err = ip_mc_validate_source(skb, daddr, saddr, tos, dev, in_dev, &itag);
	if (err)
		return err;

	if (our)
		flags |= RTCF_LOCAL;

	rth = rt_dst_alloc(dev_net(dev)->loopback_dev, flags, RTN_MULTICAST,
			   IN_DEV_ORCONF(in_dev, NOPOLICY), false);
	if (!rth)
		return -ENOBUFS;

#ifdef CONFIG_IP_ROUTE_CLASSID
	rth->dst.tclassid = itag;
#endif
	rth->dst.output = ip_rt_bug;
	rth->rt_is_input= 1;

#ifdef CONFIG_IP_MROUTE
	if (!ipv4_is_local_multicast(daddr) && IN_DEV_MFORWARD(in_dev))
		rth->dst.input = ip_mr_input;
#endif
	RT_CACHE_STAT_INC(in_slow_mc);

	skb_dst_set(skb, &rth->dst);
	return 0;
}
```

로컬 호스트가 멀티캐스트 라우터이고 IN_DEV_MFORWARD(in_indev)가 설정돼 있다면 dst의 input 콜백은 ip_mr_input()으로 설정된다.
[ip_mr_input()](https://elixir.bootlin.com/linux/latest/source/net/ipv4/ipmr.c#L2071) 함수는 멀티캐스트 패킷 포워딩을 위한 함수로, MFC(Multicast Forwarding Cache)라는 자료구조에서 유효한 항목이 발견되면 ip_mr_forward() 함수를 호출한다.
```c
int ip_mr_input(struct sk_buff *skb)
{
	...
	/* already under rcu_read_lock() */
	cache = ipmr_cache_find(mrt, ip_hdr(skb)->saddr, ip_hdr(skb)->daddr);
	...

	/* No usable cache entry */
	if (!cache) {
		...
		kfree_skb(skb);
		return -ENODEV;
	}

	read_lock(&mrt_lock);
	ip_mr_forward(net, mrt, dev, skb, cache, local);
	read_unlock(&mrt_lock);
}
```

[ip_mr_forward()](https://elixir.bootlin.com/linux/latest/source/net/ipv4/ipmr.c#L1925) 함수에서는 여러 검사를 통해 필요한 데이터들을 결정하여 ipmr_queue_xmit() 함수를 호출한다.

```c
static void ipmr_queue_xmit(struct net *net, struct mr_table *mrt,
			    int in_vifi, struct sk_buff *skb, int vifi)
{
	...

	vif->pkt_out++;
	vif->bytes_out += skb->len;

	skb_dst_drop(skb);
	skb_dst_set(skb, &rt->dst);
	ip_decrease_ttl(ip_hdr(skb));

	/* FIXME: forward and output firewalls used to be called here.
	 * What do we do with netfilter? -- RR
	 */
	if (vif->flags & VIFF_TUNNEL) {
		ip_encap(net, skb, vif->local, vif->remote);
		/* FIXME: extra output firewall step used to be here. --RR */
		vif->dev->stats.tx_packets++;
		vif->dev->stats.tx_bytes += skb->len;
	}

	IPCB(skb)->flags |= IPSKB_FORWARDED;

	/* RFC1584 teaches, that DVMRP/PIM router must deliver packets locally
	 * not only before forwarding, but after forwarding on all output
	 * interfaces. It is clear, if mrouter runs a multicasting
	 * program, it should receive packets not depending to what interface
	 * program is joined.
	 * If we will not make it, the program will have to join on all
	 * interfaces. On the other hand, multihoming host (or router, but
	 * not mrouter) cannot join to more than one interface - it will
	 * result in receiving multiple packets.
	 */
	NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD,
		net, NULL, skb, skb->dev, dev,
		ipmr_forward_finish);
	return;

out_free:
	kfree_skb(skb);
}
```

위와 같이 TTL 값을 1 감소한 후 ipmr_forward_finish() 함수를 호출한다.  

```c
static inline int ipmr_forward_finish(struct net *net, struct sock *sk,
				      struct sk_buff *skb)
{
	struct ip_options *opt = &(IPCB(skb)->opt);

	IP_INC_STATS(net, IPSTATS_MIB_OUTFORWDATAGRAMS);
	IP_ADD_STATS(net, IPSTATS_MIB_OUTOCTETS, skb->len);

	if (unlikely(opt->optlen))
		ip_forward_options(skb);

	return dst_output(net, sk, skb);
}
```

ipmr_forward_finish() 함수에서는 결국 dst_output 함수를 통해 SKB에 등록된 output callback을 호출한다.  

